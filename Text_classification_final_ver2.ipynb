{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-iPZFoQiasf"
      },
      "source": [
        "## Lab 2: Text Classification\n",
        "\n",
        "Note: For this lab exercise, it is recommended that you use [Google colab](https://colab.research.google.com/) to avoid issues concerning the deep learning module dependencies on your local system.\n",
        "\n",
        "For questions contact:\n",
        "\n",
        "Yash Pawar\n",
        "\n",
        "email ID: yash.pawar@dsv.su.se"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugaJVbFBraxp"
      },
      "source": [
        "## 1. Introduction\n",
        "\n",
        "\n",
        "In this lab exercise, we will perform classification of text into predefined classes using Machine Learning. In particular, we will be classifying the text from [BBC](http://mlg.ucd.ie/datasets/bbc.html) dataset consisting of 5 different classes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GU2tn5d_raxu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "## Suppress warnings\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE14c8aIraxv"
      },
      "source": [
        "### 2. Import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZjVIjeHXraxw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note: The filepath has been specified considerning that the notebook is run using google colab.\n",
        "\n",
        "bbc = pd.read_csv(filepath_or_buffer='bbc_text.csv', delimiter = ',')\n",
        "bbc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "082tyASTraxw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training_bbc:\n",
            "       category                                               text\n",
            "2051  business  hariri killing hits beirut shares shares in so...\n",
            "1161     sport  israeli club look to africa four african playe...\n",
            "1162     sport  moyes u-turn on beattie dismissal everton mana...\n",
            "1474  business  lufthansa may sue over bush visit german airli...\n",
            "400      sport  double injury blow strikes wales wales centre ...\n",
            "test_bbc:\n",
            "            category                                               text\n",
            "211        politics  straw attacked on china arms moves to lift the...\n",
            "1452           tech  spam e-mails tempt net shoppers computer users...\n",
            "2068           tech  online games play with politics after bubbling...\n",
            "655   entertainment  eminem secret gig venue revealed rapper eminem...\n",
            "992            tech  concern over rfid tags consumers are very conc...\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## To do: Replace the ??? with code to split the dataset into train and test set\n",
        "training_bbc, test_bbc = train_test_split(bbc)\n",
        "print(\"training_bbc:\\n\", training_bbc.head())\n",
        "print(\"test_bbc:\\n\", test_bbc.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUhRukvlraxx"
      },
      "source": [
        "### 3. Visualization\n",
        "\n",
        "Your task here is to get an understanding of distribution of different classes in the data by visualization and compare them.\n",
        "\n",
        "You are expected to generate two plots, on for each training and test dataset.\n",
        "\n",
        "You can refer to the [Bar plots tutorial](https://pythonguides.com/matplotlib-plot-bar-chart/) to know more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S15Sb8iWraxx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# To do: add the code below to plot the Distribution of classes in both the datasets.\n",
        "# Training data:\n",
        "#cnt_training = training_bbc[\"text\"].str.findall(r\"(\\w+)\").explode().value_counts()\n",
        "sentence_len = training_bbc['text'].str.len()\n",
        "plt.bar(training_bbc['category'],sentence_len)\n",
        "plt.title(\"Training data\")\n",
        "plt.ylabel(\"Number of sentences\")\n",
        "plt.xlabel(\"Categories\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJeBNjcKrax1"
      },
      "source": [
        "### 5. Classification using Naive Bayes\n",
        "\n",
        "For training and validation, we will use a [Multinomial Naive Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html). Here, you are expected to:\n",
        "\n",
        "1. Vectorize the text from the training set.\n",
        "2. Train the classifier\n",
        "3. Evaluate the classifier using the test set. \n",
        "\n",
        "Tip: You can use [sklearn's pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) functionality to perform steps 1 and 2. \n",
        "\n",
        "Tip: You can use [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to print the results of evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PEXADlvrax2"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Train and evaluate a Multinomial Naive Bayes classifier\n",
        "# To do: Add the code below to build a pipeline for the classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQR91FiQrax2"
      },
      "source": [
        "### 6. Baseline Classifier\n",
        "\n",
        "You can compare the performance of your Machine Learning model with a simple baseline classifier. One possibility could be to use a classifier that generates predictions by respecting the training setâ€™s class distribution. You can consider using [Dummy classifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) from scikit learn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZunaVeFrax3"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# Evaluate the random baseline\n",
        "baseline = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "# To do: Add the code below to train the baseline classifier and evaluate it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hoa-P1QIrax4"
      },
      "source": [
        "Is the result from the baseline classifier justified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwzvJ6qMrax4"
      },
      "source": [
        "### 6. Grid Search\n",
        "\n",
        "So far, you have trained the vectorizer and the classifer using their default parameters. However, in practical settings, one needs to optimize the parameters of the model to maximize the performance. \n",
        "\n",
        "Here, you are asked to find the optimal parameters for the pipelines that you have created above using a 5 fold cross validation. The choice of hyperparameters for optimization are:\n",
        "\n",
        "1. Bi-grams vs uni-grams vs tri-grams from [Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). \n",
        "2. Additive smoothing  for the Multinomial naive bayes classifier $\\alpha$ = {1, 0.1}\n",
        "3. Tokenized vs non-tokenized text (For tokenization, you can use the function 'preprocess' that is given below as a parameter for the vectorizer.)\n",
        "\n",
        "\n",
        "You can refer to the [Grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) documentation from the scikit-learn library.\n",
        "\n",
        "Finally, print the parameters from the grid search that give the best performance. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdhGS2HMU3Ac"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function preprocess can be used as a tokenizer.\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        " \n",
        "    final_key=[]\n",
        "    for token in doc:\n",
        "        if token.is_stop==False and token.lemma_.isalpha():\n",
        "            \n",
        "            final_key.append(token.lemma_)\n",
        "        \n",
        "    return final_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOz9OcIlrax4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# To do: Replace the ??? in the code and implement the grid search\n",
        "# Note: Take a look at how you an specify the parameters for grid search from an example of n-grams. Similarly, you can specify the other remaining parameters.\n",
        "params = {'vectorizer__ngram_range':[(1,1), (1,2), (1,3)],\n",
        "          ???,\n",
        "          ???}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8ODDYpS626Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GISqsrKD8md0"
      },
      "source": [
        "## 7. Fine-tuning using BERT\n",
        "\n",
        "In this section, you will see how a pre-trained BERT model can be fine tuned for the task of text classification. \n",
        "\n",
        "Run the following cells to fine-tune the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-zjPdPiZLEG"
      },
      "outputs": [],
      "source": [
        "'Download the tokenizer and BERT module for python'\n",
        "\n",
        "#!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "\n",
        "\n",
        "\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wks6VNo68xk-"
      },
      "outputs": [],
      "source": [
        "'Import all the necessary modules'\n",
        "\n",
        "#import tokenization\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "from tensorflow.keras.models import  Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCiSoIU28656"
      },
      "outputs": [],
      "source": [
        "'Download the pretrained BERT model'\n",
        "\n",
        "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
        "bert_layer = hub.KerasLayer(m_url, trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK-Skk-K87oz"
      },
      "outputs": [],
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "#tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "'Use BERT tokenizer'\n",
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "tokenizer=FullTokenizer(vocab_file,do_lower_case)\n",
        "\n",
        "\n",
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "        \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len-len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "        \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF_gDNZn8-LP"
      },
      "outputs": [],
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    \n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    \n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    \n",
        "    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    out = tf.keras.layers.Dense(5, activation='softmax')(lay)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM05qXjS9Bbj"
      },
      "outputs": [],
      "source": [
        "'Set the maximum length of the sequence'\n",
        "max_len = 512\n",
        "\n",
        "'Transform non-numerical labels to numerical'\n",
        "label = preprocessing.LabelEncoder()\n",
        "train_labels = label.fit_transform(training_bbc['category'])\n",
        "train_labels = to_categorical(train_labels)\n",
        "\n",
        "'Prepare the input by tokenising and padding the text sequence'\n",
        "train_input = bert_encode(training_bbc.text.values, tokenizer, max_len=max_len)\n",
        "test_input = bert_encode(test_bbc.text.values, tokenizer, max_len=max_len)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0yJERe39F1F"
      },
      "outputs": [],
      "source": [
        "labels = label.classes_\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HudNWXyS9L5z"
      },
      "outputs": [],
      "source": [
        "'Build the model'\n",
        "\n",
        "model = build_model(bert_layer, max_len=max_len)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxd085OY9Rn4"
      },
      "outputs": [],
      "source": [
        "'Start training the model'\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "\n",
        "train_sh = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=1,\n",
        "    callbacks=[checkpoint, earlystopping],\n",
        "    batch_size=4,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Zr2lw1ClM7"
      },
      "outputs": [],
      "source": [
        "'Predict the classes from the fine-tuned BERT model'\n",
        "bert_pred = model.predict(test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E9ufij-DU2q"
      },
      "outputs": [],
      "source": [
        "'Invert the classes from numerical to non-numerical (original) categories'\n",
        "y_pred_bert = label.inverse_transform(np.argmax(bert_pred.round().astype(int), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnni25tiC-Ng"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(classification_report(test_bbc['category'], y_pred_bert, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyNKl7Z6_Sj5"
      },
      "source": [
        "1. Comment on the results. Is there any improvement in performance when compared to MultinomialNB?\n",
        "\n",
        "2. Try changing the number of epochs to 3 and then 5 to see if there is any improvement in the performance. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLev7gYhF_D2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Text_classification_lab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
